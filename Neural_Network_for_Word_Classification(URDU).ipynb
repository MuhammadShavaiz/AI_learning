{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNK9igz6gdcdhm4EmB0jyqU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadShavaiz/AI_learning/blob/main/Neural_Network_for_Word_Classification(URDU).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Classification Using LSTM in PyTorch\n",
        "\n",
        "This notebook demonstrates the implementation of an LSTM-based model for classifying Urdu words as either correct or incorrect. It covers data preparation, including encoding and padding of sequences, and uses binary cross-entropy loss for training. The model's performance is evaluated through accuracy, precision, recall, and F1 score metrics, showcasing its effectiveness in word classification tasks."
      ],
      "metadata": {
        "id": "eyAkrBkDo0Q_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "RBZx8vpJouRN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "qBzLktXZM7yT",
        "outputId": "9b8c1ce4-99f1-4616-f5f5-50b4a72bd081"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'فرسٹ ایڈ وہ ابتدائی مدد ہوتی ہے جو کسی شخص کو اچانک پیش آنے والی چوٹ یا بیماری کی صورت میں دی جاتی ہے، تاکہ اُس کی حالت مزید خراب ہونے سے بچ سکے، زندگی محفوظ رہے اور طبی مدد پہنچنے تک صحتیابی کا عمل شروع ہو جائے۔ یہ عموماً کوئی ایسا فرد دیتا ہے جسے ابتدائی طبی امداد کا بنیادی علم ہوتا ہے۔ جسمانی صحت کے علاوہ ذہنی صحت کے مسائل میں بھی فرسٹ ایڈ دی جا سکتی ہے، جیسے کہ ذہنی دباؤ یا پوسٹ ٹرامیٹک اسٹریس ڈس آرڈر (PTSD) میں مبتلا افراد کے لیے نفسیاتی فرسٹ ایڈ۔\\n\\nدنیا بھر میں مختلف مقامات اور حالات میں فرسٹ ایڈ کی ضرورت پیش آ سکتی ہے۔ اکثر ممالک میں مختلف قوانین اور ہدایات موجود ہوتی ہیں جو کچھ مخصوص حالات میں فرسٹ ایڈ کی فراہمی کو لازمی قرار دیتی ہیں، جیسے کہ کام کی جگہ پر فرسٹ ایڈ کی تربیت یا کچھ ضروری آلات کا موجود ہونا (مثلاً ڈیفبریلیٹر)۔\\n\\nفرسٹ ایڈ کے پانچ بنیادی مراحل ہوتے ہیں: حالات کا جائزہ لینا، اگر خطرہ ہو تو محفوظ مقام پر منتقل ہونا، مدد کے لیے پکارنا، موزوں فرسٹ ایڈ فراہم کرنا اور آخر میں مریض کی حالت کا دوبارہ جائزہ لینا۔\\n\\nتاریخ میں فرسٹ ایڈ کا ذکر خاص طور پر جنگوں کے دوران ملتا ہے جہاں زخمی فوجیوں کو ابتدائی طبی امداد فراہم کی جاتی تھی۔ قدیم رومی فوج میں ایک نظام موجود تھا جس میں فرسٹ ایڈ فراہم کرنے والے افراد کو تربیت دی جاتی تھی۔\\n\\nجدید دور میں فرسٹ ایڈ کی باضابطہ تربیت 18ویں صدی کے آخر میں شروع ہوئی، جب ڈوبنے کے واقعات عام تھے اور زندگی بچانے کے طریقے سکھائے جانے لگے۔ 19ویں صدی میں ریڈ کراس اور ریڈ کریسنٹ تنظیموں کی بنیاد رکھی گئی، جو آج بھی دنیا بھر میں فرسٹ ایڈ فراہم کرنے والی سب سے بڑی تنظیمیں ہیں۔\\n\\nفرسٹ ایڈ کا بنیادی مقصد مریض کی جان بچانا، اُس کی حالت کو مزید بگڑنے سے روکنا اور صحتیابی کی راہ ہموار کرنا ہے۔ فرسٹ ایڈ نہ صرف فوری مدد فراہم کرتی ہے بلکہ مریض کی تکلیف کو کم کرنے میں بھی مدد دیتی ہے اور اُسے پرسکون کرنے کا کام کرتی ہے۔\\n\\nفرسٹ ایڈ میں \"ABC\" کا اصول بہت اہمیت رکھتا ہے، جس کا مطلب ہے ایئر وے (سانس کی نالی کھلی رکھنا)، بریتھنگ (سانس لینے میں مدد دینا) اور سرکولیشن (خون کی روانی کو برقرار رکھنا)۔ ان بنیادی اصولوں پر عمل کرتے ہوئے زندگی بچانے میں کامیابی حاصل کی جا سکتی ہے'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "corpus = \"\"\"فرسٹ ایڈ وہ ابتدائی مدد ہوتی ہے جو کسی شخص کو اچانک پیش آنے والی چوٹ یا بیماری کی صورت میں دی جاتی ہے، تاکہ اُس کی حالت مزید خراب ہونے سے بچ سکے، زندگی محفوظ رہے اور طبی مدد پہنچنے تک صحتیابی کا عمل شروع ہو جائے۔ یہ عموماً کوئی ایسا فرد دیتا ہے جسے ابتدائی طبی امداد کا بنیادی علم ہوتا ہے۔ جسمانی صحت کے علاوہ ذہنی صحت کے مسائل میں بھی فرسٹ ایڈ دی جا سکتی ہے، جیسے کہ ذہنی دباؤ یا پوسٹ ٹرامیٹک اسٹریس ڈس آرڈر (PTSD) میں مبتلا افراد کے لیے نفسیاتی فرسٹ ایڈ۔\n",
        "\n",
        "دنیا بھر میں مختلف مقامات اور حالات میں فرسٹ ایڈ کی ضرورت پیش آ سکتی ہے۔ اکثر ممالک میں مختلف قوانین اور ہدایات موجود ہوتی ہیں جو کچھ مخصوص حالات میں فرسٹ ایڈ کی فراہمی کو لازمی قرار دیتی ہیں، جیسے کہ کام کی جگہ پر فرسٹ ایڈ کی تربیت یا کچھ ضروری آلات کا موجود ہونا (مثلاً ڈیفبریلیٹر)۔\n",
        "\n",
        "فرسٹ ایڈ کے پانچ بنیادی مراحل ہوتے ہیں: حالات کا جائزہ لینا، اگر خطرہ ہو تو محفوظ مقام پر منتقل ہونا، مدد کے لیے پکارنا، موزوں فرسٹ ایڈ فراہم کرنا اور آخر میں مریض کی حالت کا دوبارہ جائزہ لینا۔\n",
        "\n",
        "تاریخ میں فرسٹ ایڈ کا ذکر خاص طور پر جنگوں کے دوران ملتا ہے جہاں زخمی فوجیوں کو ابتدائی طبی امداد فراہم کی جاتی تھی۔ قدیم رومی فوج میں ایک نظام موجود تھا جس میں فرسٹ ایڈ فراہم کرنے والے افراد کو تربیت دی جاتی تھی۔\n",
        "\n",
        "جدید دور میں فرسٹ ایڈ کی باضابطہ تربیت 18ویں صدی کے آخر میں شروع ہوئی، جب ڈوبنے کے واقعات عام تھے اور زندگی بچانے کے طریقے سکھائے جانے لگے۔ 19ویں صدی میں ریڈ کراس اور ریڈ کریسنٹ تنظیموں کی بنیاد رکھی گئی، جو آج بھی دنیا بھر میں فرسٹ ایڈ فراہم کرنے والی سب سے بڑی تنظیمیں ہیں۔\n",
        "\n",
        "فرسٹ ایڈ کا بنیادی مقصد مریض کی جان بچانا، اُس کی حالت کو مزید بگڑنے سے روکنا اور صحتیابی کی راہ ہموار کرنا ہے۔ فرسٹ ایڈ نہ صرف فوری مدد فراہم کرتی ہے بلکہ مریض کی تکلیف کو کم کرنے میں بھی مدد دیتی ہے اور اُسے پرسکون کرنے کا کام کرتی ہے۔\n",
        "\n",
        "فرسٹ ایڈ میں \"ABC\" کا اصول بہت اہمیت رکھتا ہے، جس کا مطلب ہے ایئر وے (سانس کی نالی کھلی رکھنا)، بریتھنگ (سانس لینے میں مدد دینا) اور سرکولیشن (خون کی روانی کو برقرار رکھنا)۔ ان بنیادی اصولوں پر عمل کرتے ہوئے زندگی بچانے میں کامیابی حاصل کی جا سکتی ہے\"\"\"\n",
        "corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization. Generating incorrect words"
      ],
      "metadata": {
        "id": "XhCFTQnqT2Qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "correct_words = list(corpus.split())\n",
        "# Helper function to add random prefix/suffix\n",
        "def add_random_prefix_suffix(word, num_chars=2):\n",
        "    random_chars = ''.join(random.choices(list(\"ابپتثجچحخدذرزسشصضطظعغفقکگلمنوهیءٔ\"), k=num_chars))\n",
        "    return random_chars + word + random_chars\n",
        "def generate_invalid_words(valid_words):\n",
        "    invalid_words = []\n",
        "    for word in valid_words:\n",
        "      invalid_word = add_random_prefix_suffix(word)\n",
        "      invalid_words.append(invalid_word)\n",
        "    return invalid_words\n",
        "incorrect_words = generate_invalid_words(correct_words)\n",
        "print(f'correct words example:{correct_words[:5]}')\n",
        "print(f'incorrect words example:{incorrect_words[:5]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crKAkniRUkpG",
        "outputId": "43f0b187-b8aa-4826-a606-6d1a2a5db022"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct words example:['فرسٹ', 'ایڈ', 'وہ', 'ابتدائی', 'مدد']\n",
            "incorrect words example:['طٔفرسٹطٔ', 'ءلایڈءل', 'ثبوہثب', 'ءاابتدائیءا', 'تٔمددتٔ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Dataset(valid + non-valid words)"
      ],
      "metadata": {
        "id": "qwrZpshRXIJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(valid_words, invalid_words):\n",
        "    data = [(word, 1) for word in valid_words] + [(word, 0) for word in invalid_words]\n",
        "    random.shuffle(data)  # Shuffle data to avoid ordered patterns\n",
        "    return data\n",
        "\n",
        "# Example usage\n",
        "dataset = create_dataset(correct_words, incorrect_words)\n",
        "\n",
        "# Print a sample\n",
        "for word, label in dataset[:5]:\n",
        "    print(f'Word: {word}, Label: {label}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_VK9ECgVoOt",
        "outputId": "6767c56a-95c7-43d7-d23d-94eee1544ac7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: خوکوخو, Label: 0\n",
            "Word: قرتھی۔قر, Label: 0\n",
            "Word: صسسےصس, Label: 0\n",
            "Word: مراحل, Label: 1\n",
            "Word: خطوالیخط, Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataPreprocessing: One Hot Encoding"
      ],
      "metadata": {
        "id": "BegljkSdXeoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from collections import defaultdict\n",
        "\n",
        "# Get all unique Urdu characters\n",
        "all_chars = set(''.join(correct_words + incorrect_words))\n",
        "char_to_idx = {char: idx for idx, char in enumerate(all_chars)}\n",
        "\n",
        "def encode_word(word):\n",
        "    return [char_to_idx[char] for char in word]"
      ],
      "metadata": {
        "id": "IZ31dPVmXW4I"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Dataset and DataLoader"
      ],
      "metadata": {
        "id": "ZTyj2Fv5boba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader,random_split\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class WordDataset(Dataset):\n",
        "    def __init__(self, correct_words, incorrect_words, char_to_idx):\n",
        "        self.data = [(encode_word(word), 1) for word in correct_words] + [(encode_word(word), 0) for word in incorrect_words]\n",
        "        self.char_to_idx = char_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        word, label = self.data[idx]\n",
        "        return torch.tensor(word, dtype=torch.long), torch.tensor(label, dtype=torch.float)\n",
        "# Custom collate function to pad sequences\n",
        "def collate_fn(batch):\n",
        "    words, labels = zip(*batch)  # Unzip the batch\n",
        "    words_padded = pad_sequence(words, batch_first=True, padding_value=0)  # Pad sequences\n",
        "    labels = torch.stack(labels)  # Stack labels into a tensor\n",
        "    return words_padded, labels\n",
        "\n",
        "# Prepare dataset and dataloader\n",
        "dataset = WordDataset(correct_words, incorrect_words, char_to_idx)\n",
        "# Split dataset into 80% training and 20% test\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Create DataLoaders for training and testing\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "hDPEcwRObAC9"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network"
      ],
      "metadata": {
        "id": "5cIr-HaRcYxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class WordClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(WordClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)  # Convert characters to embeddings\n",
        "        lstm_out, _ = self.lstm(embedded)  # LSTM output\n",
        "        lstm_out = lstm_out[:, -1, :]  # Use only the last LSTM output\n",
        "        out = self.fc(lstm_out)\n",
        "        return torch.sigmoid(out)\n",
        "\n",
        "# Hyperparameters\n",
        "vocab_size = len(char_to_idx)  # Number of unique characters\n",
        "embed_dim = 10  # Embedding dimension\n",
        "hidden_dim = 20  # LSTM hidden state size\n",
        "\n",
        "# Initialize the model\n",
        "urdu_model = WordClassifier(vocab_size, embed_dim, hidden_dim)"
      ],
      "metadata": {
        "id": "x4sbminocF-t"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "uRAT46QbccCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(urdu_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for words, labels in train_loader:\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = urdu_model(words)\n",
        "        if outputs.dim == 0:\n",
        "          outputs = outputs.view(4, 1)\n",
        "        labels = labels.view(-1,1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJfZjB0ccUKi",
        "outputId": "85cbad0b-e585-4272-b246-509a1ac41425"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.3077\n",
            "Epoch [2/100], Loss: 1.1016\n",
            "Epoch [3/100], Loss: 0.9779\n",
            "Epoch [4/100], Loss: 0.5847\n",
            "Epoch [5/100], Loss: 0.0415\n",
            "Epoch [6/100], Loss: 0.0249\n",
            "Epoch [7/100], Loss: 0.5917\n",
            "Epoch [8/100], Loss: 1.1476\n",
            "Epoch [9/100], Loss: 0.5901\n",
            "Epoch [10/100], Loss: 0.0634\n",
            "Epoch [11/100], Loss: 2.1435\n",
            "Epoch [12/100], Loss: 0.0100\n",
            "Epoch [13/100], Loss: 0.1447\n",
            "Epoch [14/100], Loss: 0.5004\n",
            "Epoch [15/100], Loss: 0.8914\n",
            "Epoch [16/100], Loss: 0.1003\n",
            "Epoch [17/100], Loss: 0.2888\n",
            "Epoch [18/100], Loss: 0.0153\n",
            "Epoch [19/100], Loss: 0.0045\n",
            "Epoch [20/100], Loss: 0.0539\n",
            "Epoch [21/100], Loss: 0.1781\n",
            "Epoch [22/100], Loss: 0.1461\n",
            "Epoch [23/100], Loss: 0.5685\n",
            "Epoch [24/100], Loss: 0.1693\n",
            "Epoch [25/100], Loss: 0.0217\n",
            "Epoch [26/100], Loss: 1.8520\n",
            "Epoch [27/100], Loss: 0.0202\n",
            "Epoch [28/100], Loss: 0.0016\n",
            "Epoch [29/100], Loss: 0.1182\n",
            "Epoch [30/100], Loss: 0.4335\n",
            "Epoch [31/100], Loss: 0.0134\n",
            "Epoch [32/100], Loss: 0.0069\n",
            "Epoch [33/100], Loss: 0.0301\n",
            "Epoch [34/100], Loss: 0.0153\n",
            "Epoch [35/100], Loss: 0.1297\n",
            "Epoch [36/100], Loss: 0.0132\n",
            "Epoch [37/100], Loss: 0.1029\n",
            "Epoch [38/100], Loss: 0.0855\n",
            "Epoch [39/100], Loss: 0.0063\n",
            "Epoch [40/100], Loss: 0.0017\n",
            "Epoch [41/100], Loss: 0.0819\n",
            "Epoch [42/100], Loss: 0.1941\n",
            "Epoch [43/100], Loss: 0.0008\n",
            "Epoch [44/100], Loss: 0.4210\n",
            "Epoch [45/100], Loss: 0.0055\n",
            "Epoch [46/100], Loss: 0.0095\n",
            "Epoch [47/100], Loss: 0.4453\n",
            "Epoch [48/100], Loss: 0.9093\n",
            "Epoch [49/100], Loss: 0.0010\n",
            "Epoch [50/100], Loss: 0.0141\n",
            "Epoch [51/100], Loss: 0.0014\n",
            "Epoch [52/100], Loss: 0.0231\n",
            "Epoch [53/100], Loss: 0.0206\n",
            "Epoch [54/100], Loss: 0.0048\n",
            "Epoch [55/100], Loss: 0.0056\n",
            "Epoch [56/100], Loss: 0.0005\n",
            "Epoch [57/100], Loss: 0.0010\n",
            "Epoch [58/100], Loss: 0.0140\n",
            "Epoch [59/100], Loss: 0.0019\n",
            "Epoch [60/100], Loss: 0.0006\n",
            "Epoch [61/100], Loss: 0.1735\n",
            "Epoch [62/100], Loss: 0.0015\n",
            "Epoch [63/100], Loss: 0.0026\n",
            "Epoch [64/100], Loss: 0.0270\n",
            "Epoch [65/100], Loss: 0.0081\n",
            "Epoch [66/100], Loss: 0.0006\n",
            "Epoch [67/100], Loss: 0.0006\n",
            "Epoch [68/100], Loss: 0.0007\n",
            "Epoch [69/100], Loss: 0.0083\n",
            "Epoch [70/100], Loss: 0.0087\n",
            "Epoch [71/100], Loss: 0.0033\n",
            "Epoch [72/100], Loss: 0.2194\n",
            "Epoch [73/100], Loss: 0.0014\n",
            "Epoch [74/100], Loss: 0.0144\n",
            "Epoch [75/100], Loss: 0.1642\n",
            "Epoch [76/100], Loss: 0.1046\n",
            "Epoch [77/100], Loss: 0.0057\n",
            "Epoch [78/100], Loss: 0.0030\n",
            "Epoch [79/100], Loss: 0.0038\n",
            "Epoch [80/100], Loss: 0.0004\n",
            "Epoch [81/100], Loss: 0.0005\n",
            "Epoch [82/100], Loss: 0.0003\n",
            "Epoch [83/100], Loss: 0.0218\n",
            "Epoch [84/100], Loss: 0.0007\n",
            "Epoch [85/100], Loss: 0.0029\n",
            "Epoch [86/100], Loss: 0.0002\n",
            "Epoch [87/100], Loss: 0.0017\n",
            "Epoch [88/100], Loss: 0.0054\n",
            "Epoch [89/100], Loss: 0.0035\n",
            "Epoch [90/100], Loss: 0.0002\n",
            "Epoch [91/100], Loss: 0.0038\n",
            "Epoch [92/100], Loss: 0.0001\n",
            "Epoch [93/100], Loss: 0.0001\n",
            "Epoch [94/100], Loss: 0.0174\n",
            "Epoch [95/100], Loss: 0.0006\n",
            "Epoch [96/100], Loss: 0.0016\n",
            "Epoch [97/100], Loss: 0.0001\n",
            "Epoch [98/100], Loss: 0.0004\n",
            "Epoch [99/100], Loss: 0.0008\n",
            "Epoch [100/100], Loss: 0.0033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "qJ243zzpcn7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    all_labels = []\n",
        "    all_outputs = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient tracking\n",
        "        for words, labels in data_loader:\n",
        "            # Move data to the specified device (CPU or GPU)\n",
        "            words, labels = words.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(words)\n",
        "            all_outputs.append(outputs.cpu().numpy())  # Collect outputs\n",
        "            all_labels.append(labels.cpu().numpy())    # Collect labels\n",
        "\n",
        "    # Concatenate all outputs and labels\n",
        "    all_outputs = np.concatenate(all_outputs)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    # Convert probabilities to binary predictions (0 or 1)\n",
        "    binary_predictions = (all_outputs >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(all_labels, binary_predictions)\n",
        "    precision = precision_score(all_labels, binary_predictions)\n",
        "    recall = recall_score(all_labels, binary_predictions)\n",
        "    f1 = f1_score(all_labels, binary_predictions)\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Use the function to evaluate your model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Device agnostic\n",
        "urdu_model.to(device)  # Ensure your model is on the correct device\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "accuracy, precision, recall, f1 = evaluate_model(urdu_model, test_loader, device)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPcs11FzeRFF",
        "outputId": "3387bcf8-ff42-4ab6-9035-43101cef3bc1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9693\n",
            "Precision: 0.9875\n",
            "Recall: 0.9518\n",
            "F1 Score: 0.9693\n"
          ]
        }
      ]
    }
  ]
}